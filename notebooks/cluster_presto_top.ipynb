{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef150a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee7342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir_validation_set = Path(\"/home/lien002/nobackup_lien002/projects/scs/antismash_dataset_scs/output/output_ipresto_main_set\")\n",
    "input_file = outdir_main_set / \"presto_top\" / \"matches_per_topic_filtered.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40588c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenised_genes_from_match_line(match_line):\n",
    "    tokenised_genes = list()\n",
    "    match = match_line.split()[2]\n",
    "    for gene_and_topic_prob in match.split(\",\"):\n",
    "        gene, gene_to_topic_prob = gene_and_topic_prob.split(\":\")\n",
    "        tokenised_genes.append(gene)\n",
    "    return tokenised_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "subcluster_matches = defaultdict(list)\n",
    "with open(input_file, \"r\") as infile:\n",
    "    for line in infile: \n",
    "        # skip header lines\n",
    "        if line.startswith(\"#\"): \n",
    "            continue\n",
    "        tokenised_genes = get_tokenised_genes_from_match_line(line)\n",
    "        if len(tokenised_genes) < 2:\n",
    "            # skip matches with less than 2 (unique) genes\n",
    "            continue\n",
    "        bgc_id = line.split()[3]\n",
    "        subcluster_matches[tokenised_genes].append(bgc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd52d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_modules = list(subcluster_matches.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04593ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "I am writing code in python and have a list of sets called top_modules.\n",
    "\n",
    "use k_means clustering to cluster the sets. First transform it into a sparse binary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c007de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmeans(\n",
    "    sparse_m, modules, num_clusters, rownames, colnames, prefix, header, cores=1\n",
    "):\n",
    "    \"\"\"Kmeans clustering on sparse_m with num_clusters and writes to file\n",
    "\n",
    "    sparse_m: csr_matrix, shape(n_samples, n_features)\n",
    "    modules: dict {mod_num:[info,modules]}\n",
    "    num_clusters: int, number of clusters\n",
    "    rownames: list of ints, [mod_nums], sequential mod_nums, keeping track of\n",
    "        rows of sparse_m\n",
    "    colnames: list of str, all domains sequential order to keep track of\n",
    "        columns of sparse_m\n",
    "    prefix: str, prefix of outfile\n",
    "    cores: int, amount of cores to use\n",
    "    header: str, header of module file\n",
    "    \"\"\"\n",
    "    print(\"\\nRunning k-means\")\n",
    "    # outfiles\n",
    "    kmeans_pre = f\"_{num_clusters}_families\"\n",
    "    out_mods = prefix + kmeans_pre + \".txt\"\n",
    "    out_clusts = prefix + kmeans_pre + \"_by_family.txt\"\n",
    "\n",
    "    # running algorithm\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=num_clusters,\n",
    "        n_init=20,\n",
    "        max_iter=1000,\n",
    "        random_state=595,\n",
    "        verbose=0,\n",
    "        tol=0.000001,\n",
    "        n_jobs=cores,\n",
    "    ).fit(sparse_m)\n",
    "    print(kmeans)\n",
    "    clust_centers = sp.csr_matrix(kmeans.cluster_centers_)\n",
    "    labels = kmeans.labels_\n",
    "    cluster_dict = defaultdict(list)\n",
    "    np.set_printoptions(precision=2)\n",
    "    print(\"Within-cluster sum-of-squares (inertia):\", kmeans.inertia_)\n",
    "    # link each module to a family/k-means cluster\n",
    "    with open(out_mods, \"w\") as outf:\n",
    "        outf.write(header + \"\\tFamily\\n\")\n",
    "        for subcl, cl in zip(rownames, labels):\n",
    "            cluster_dict[cl].append(subcl)\n",
    "            outf.write(\n",
    "                \"{}\\t{}\\t{}\\n\".format(subcl, \"\\t\".join(modules[subcl]), cl)\n",
    "            )\n",
    "    # write file of listing all families/clusters by family with their modules\n",
    "    avg_clst_size = []\n",
    "    with open(out_clusts, \"w\") as outf_c:\n",
    "        for i in range(clust_centers.shape[0]):\n",
    "            matches = cluster_dict[i]\n",
    "            l_matches = len(matches)\n",
    "            avg_clst_size.append(l_matches)\n",
    "            counts = Counter(\n",
    "                [dom for m in matches for dom in modules[m][-1].split(\",\")]\n",
    "            )\n",
    "            spars = clust_centers[i]\n",
    "            feat_inds = spars.nonzero()[1]\n",
    "            feat_tups = [(spars[0, ind], colnames[ind]) for ind in feat_inds]\n",
    "            feat_format = [\n",
    "                \"{}:{:.2f}\".format(dom, float(score))\n",
    "                for score, dom in sorted(feat_tups, reverse=True)\n",
    "            ]\n",
    "            outf_c.write(\n",
    "                \"#Subcluster-family {}, {} subclusters\\n\".format(i, l_matches)\n",
    "            )\n",
    "            outf_c.write(\n",
    "                \"#Occurrences: {}\\n\".format(\n",
    "                    \", \".join(\n",
    "                        [dom + \":\" + str(c) for dom, c in counts.most_common()]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            outf_c.write(\"#Features: {}\\n\".format(\", \".join(feat_format)))\n",
    "            # maybe as a score the distance to the cluster center?\n",
    "            for match in matches:\n",
    "                outf_c.write(\n",
    "                    \"{}\\t{}\\n\".format(match, \"\\t\".join(modules[match]))\n",
    "                )\n",
    "    print(\"\\nAverage clustersize:\", np.mean(avg_clst_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subcluster_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
